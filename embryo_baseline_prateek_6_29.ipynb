{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of embryo_baseline_prateek.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prateekkalakuntla/Martin-Lab-Machine-Learning/blob/master/embryo_baseline_prateek_6_29.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXoLfcvznPF4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7a710601-37f0-41b9-f923-50b548b84dd0"
      },
      "source": [
        "#mounting drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "drive.mount(\"/content/drive\", force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amQaPE14ndxV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "f28d5e77-9844-4a9e-a108-af6279d44a97"
      },
      "source": [
        "# HANNAH ADDED\n",
        "!pip install keras-layer-normalization"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras-layer-normalization in /usr/local/lib/python3.6/dist-packages (0.14.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras-layer-normalization) (1.18.5)\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (from keras-layer-normalization) (2.3.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras->keras-layer-normalization) (2.10.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-layer-normalization) (1.0.8)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-layer-normalization) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras->keras-layer-normalization) (3.13)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-layer-normalization) (1.12.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-layer-normalization) (1.1.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfTtb0synh5k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Config:\n",
        "  DATASET_PATH =\"/content/drive/My Drive/EmbryoMachineLearning/Autoencoder_UCSD/UCSD_Anomaly_Dataset.v1p2/Embryo_Anomaly/Pulsing_Train\"\n",
        "  TEST_PATH = \"/content/drive/My Drive/EmbryoMachineLearning/Autoencoder_UCSD/UCSD_Anomaly_Dataset.v1p2/Embryo_Anomaly/Pulsing_Mutants\"\n",
        "  SINGLE_TEST_PATH = \"/content/drive/My Drive/EmbryoMachineLearning/Autoencoder_UCSD/UCSD_Anomaly_Dataset.v1p2/Embryo_Anomaly/Pulsing_Train/Movie_10\"\n",
        "  #batch size cannot be larger than 20 for color images\n",
        "  BATCH_SIZE = 1\n",
        "  #Past 10 epochs not very valuable\n",
        "  EPOCHS = 10\n",
        "  MODEL_PATH = \"/content/drive/My Drive/EmbryoMachineLearning/Autoencoder_UCSD/UCSD_Anomaly_Dataset.v1p2/embryo_model_prateek_fewer_frames.hdf5\""
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSemLtWInmWr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from os import listdir\n",
        "from os.path import isfile, join, isdir\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import random\n",
        "\n",
        "#Code Block 1\n",
        "def get_clips_by_stride(stride, frames_list, sequence_size):\n",
        "    \"\"\" For data augmenting purposes.\n",
        "    Parameters\n",
        "    ----------\n",
        "    stride : int\n",
        "        The distance between two consecutive frames\n",
        "    frames_list : list\n",
        "        A list of sorted frames of shape 256 X 256\n",
        "    sequence_size: int\n",
        "        The size of the lstm sequence\n",
        "    Returns\n",
        "    -------\n",
        "    list\n",
        "      A list of clips , 10 frames each\n",
        "    \"\"\"\n",
        "    clips = []\n",
        "    sz = len(frames_list)\n",
        "    #changed input shape to 3\n",
        "    clip = np.zeros(shape=(sequence_size, 256, 256, 3))\n",
        "    cnt = 0\n",
        "    cnt2 = 0\n",
        "    for start in range(0, stride):\n",
        "        for i in range(start, sz, stride):\n",
        "            clip[cnt, :, :, :] = frames_list[i]\n",
        "            cnt = cnt + 1\n",
        "            if cnt == sequence_size:\n",
        "                clips.append(clip)\n",
        "                clip = np.zeros(shape=(sequence_size, 256, 256, 3))\n",
        "                cnt = 0\n",
        "    return clips\n",
        "\n",
        "#Code Block 2\n",
        "def get_training_set():\n",
        "    \"\"\"\n",
        "    Returns\n",
        "    -------\n",
        "    list\n",
        "        A list of training sequences of shape (NUMBER_OF_SEQUENCES,SINGLE_SEQUENCE_SIZE,FRAME_WIDTH,FRAME_HEIGHT,1)\n",
        "    \"\"\"\n",
        "    new_clips = []\n",
        "    i = 0 \n",
        "    # loop over the training folders (Train000,Train001,..)\n",
        "    new_list = listdir(Config.DATASET_PATH)\n",
        "    random.shuffle(new_list)\n",
        "    list_of_movies = []\n",
        "    for f in new_list:\n",
        "        #Prateek control images, 31 images\n",
        "        print(f)\n",
        "        if f == 'Movie_01' or f == 'Movie_02' or f == 'Movie_03' or f == 'Movie_04' or f == 'Movie_05':\n",
        "          break\n",
        "        i += 1\n",
        "        if i == 11:\n",
        "          break\n",
        "        list_of_movies.append(f)\n",
        "        print(\"looping...\")\n",
        "        directory_path = join(Config.DATASET_PATH, f)\n",
        "        if isdir(directory_path):\n",
        "            all_frames = []\n",
        "            # loop over all the images in the folder (0.tif,1.tif,..,199.tif)\n",
        "            for c in sorted(listdir(directory_path)):\n",
        "                img_path = join(directory_path, c)\n",
        "                if str(img_path)[-3:] == \"jpg\":\n",
        "                    img = Image.open(img_path).resize((256, 256))\n",
        "                    #black and white\n",
        "                    #img = np.dot(img,[.299,.587,.144])\n",
        "                    img = np.array(img)/256\n",
        "                    all_frames.append(img)\n",
        "            #get the 10-frames sequences from the list of images after applying data augmentation\n",
        "            for stride in range(1, 3):\n",
        "                #Increasing number of frames increases the accuracy, 15 is my favorite right now\n",
        "                new_clips.extend(get_clips_by_stride(stride=stride, frames_list=all_frames, sequence_size=15))\n",
        "    print(\"done looping.\")\n",
        "    return new_clips, list_of_movies"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hp-CrzpAnn6U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f8a8c21e-a786-4366-ce9c-ea7ed13185de"
      },
      "source": [
        "import keras\n",
        "from keras.layers import Conv2DTranspose, ConvLSTM2D, BatchNormalization, TimeDistributed, Conv2D\n",
        "from keras.models import Sequential, load_model\n",
        "from keras_layer_normalization import LayerNormalization\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def get_model(training_set, reload_model):\n",
        "    \"\"\"\n",
        "    Parameters\n",
        "    ----------\n",
        "    reload_model : bool\n",
        "        Load saved model or retrain it\n",
        "    \"\"\"\n",
        "    if not reload_model:\n",
        "        return load_model(Config.MODEL_PATH,custom_objects={'LayerNormalization': LayerNormalization})\n",
        "    print(\"4\")\n",
        "    training_set = np.array(training_set)\n",
        "    print(\"5\")\n",
        "    seq = Sequential()\n",
        "    print(\"6\")\n",
        "\n",
        "    #Prateek changed batch input shape to last item = 3\n",
        "    seq.add(TimeDistributed(Conv2D(128, (11, 11), strides=4, padding=\"same\"), batch_input_shape=(None, 15, 256, 256, 3)))\n",
        "    seq.add(LayerNormalization())\n",
        "    seq.add(TimeDistributed(Conv2D(64, (5, 5), strides=2, padding=\"same\")))\n",
        "    \n",
        "    # # # # #\n",
        "    seq.add(ConvLSTM2D(64, (3, 3), padding=\"same\", return_sequences=True))\n",
        "    seq.add(LayerNormalization())\n",
        "    seq.add(ConvLSTM2D(32, (3, 3), padding=\"same\", return_sequences=True))\n",
        "    seq.add(LayerNormalization())\n",
        "    seq.add(ConvLSTM2D(64, (3, 3), padding=\"same\", return_sequences=True))\n",
        "    seq.add(LayerNormalization())\n",
        "    # # # # #\n",
        "    seq.add(LayerNormalization())\n",
        "    seq.add(TimeDistributed(Conv2DTranspose(64, (5, 5), strides=2, padding=\"same\")))\n",
        "    seq.add(LayerNormalization())\n",
        "    seq.add(TimeDistributed(Conv2DTranspose(128, (11, 11), strides=4, padding=\"same\")))\n",
        "    seq.add(LayerNormalization())\n",
        "    seq.add(TimeDistributed(Conv2D(3, (11, 11), activation=\"sigmoid\", padding=\"same\")))\n",
        "\n",
        "    print(seq.summary())\n",
        "    seq.compile(loss='mse', optimizer=keras.optimizers.Adam(lr=1e-4, decay=1e-5, epsilon=1e-6))\n",
        "    seq.fit(training_set, training_set,\n",
        "            batch_size=Config.BATCH_SIZE, epochs=Config.EPOCHS, shuffle=False)\n",
        "    seq.save(Config.MODEL_PATH)\n",
        "    return seq"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PghC2Y0Rn1gW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_single_test(test):\n",
        "    #Prateek changed sz \n",
        "    sz = len(listdir(test))\n",
        "    final = np.zeros(shape=(sz, 256, 256, 3))\n",
        "    cnt = 0\n",
        "    for f in sorted(listdir(test)):\n",
        "        if str(join(test, f))[-3:] == \"jpg\":\n",
        "            img = Image.open(join(test, f)).resize((256, 256))\n",
        "            #Black and white\n",
        "            #img = np.dot(img, [.299,.587,.144])\n",
        "            img = np.array(img, dtype=np.float32) / 256.0\n",
        "            final[cnt, :, :, :] = img\n",
        "            cnt = cnt + 1\n",
        "    return final"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "om_AkfTen5E4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def evaluate(training_set, out_model):\n",
        "    print(\"starting\")\n",
        "    model = get_model(training_set, out_model)\n",
        "    # Hannah changed\n",
        "    #model = get_model(False)\n",
        "    print(\"got model\")\n",
        "    test = get_single_test(Config.SINGLE_TEST_PATH)\n",
        "    print(\"got test\")\n",
        "    sz = test.shape[0] - 15\n",
        "    sequences = np.zeros((sz, 15, 256, 256, 3))\n",
        "    # apply the sliding window technique to get the sequences\n",
        "    for i in range(0, sz):\n",
        "        clip = np.zeros((15, 256, 256, 3))\n",
        "        for j in range(0, 15):\n",
        "            clip[j] = test[i + j, :, :, :]\n",
        "        sequences[i] = clip\n",
        "\n",
        "    # get the reconstruction cost of all the sequences\n",
        "    reconstructed_sequences = model.predict(sequences,batch_size=2)\n",
        "    sequences_reconstruction_cost = np.array([np.linalg.norm(np.subtract(sequences[i],reconstructed_sequences[i])) for i in range(0,sz)])\n",
        "    sa = (sequences_reconstruction_cost - np.min(sequences_reconstruction_cost)) / np.max(sequences_reconstruction_cost)\n",
        "    sr = 1.0 - sa\n",
        "\n",
        "    # plot the regularity scores\n",
        "    plt.plot(sr)\n",
        "    plt.ticklabel_format(useOffset=False)\n",
        "    plt.ylabel('regularity score Sr(t)')\n",
        "    plt.xlabel('frame t')\n",
        "    plt.show()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJkjhkIxwVM6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Returns average accuracy for 5 random WT movies that the model has not seen\n",
        "def get_accuracy_WT(list_of_movies):\n",
        "  model = get_model(training_set, False)\n",
        "  new_list = listdir(Config.DATASET_PATH)\n",
        "  random.shuffle(new_list)\n",
        "  total_loss = []\n",
        "  val = 0\n",
        "  for f in new_list:\n",
        "      #Prateek control images, 31 images\n",
        "      if f in list_of_movies:\n",
        "        continue\n",
        "      print(f)\n",
        "      val += 1\n",
        "      print(val)\n",
        "      if val == 6:\n",
        "        break\n",
        "      directory_path = join(Config.DATASET_PATH, f)\n",
        "      test = get_single_test(directory_path)\n",
        "      print(\"got test\")\n",
        "      sz = test.shape[0] - 15\n",
        "      sequences = np.zeros((sz, 15, 256, 256, 3))\n",
        "      # apply the sliding window technique to get the sequences\n",
        "      for i in range(0, sz):\n",
        "          clip = np.zeros((15, 256, 256, 3))\n",
        "          for j in range(0, 15):\n",
        "              clip[j] = test[i + j, :, :, :]\n",
        "          sequences[i] = clip\n",
        "  \n",
        "      reconstructed_sequences = model.predict(sequences,batch_size=2)\n",
        "      sequences_reconstruction_cost = np.array([np.linalg.norm(np.subtract(sequences[i],reconstructed_sequences[i])) for i in range(0,sz)])\n",
        "      sa = (sequences_reconstruction_cost - np.min(sequences_reconstruction_cost)) / np.max(sequences_reconstruction_cost)\n",
        "      loss = 1 - sum(sa)/len(sa)\n",
        "      total_loss.append((loss, f))\n",
        "  return total_loss\n",
        "\n",
        "def get_accuracy_mut():\n",
        "  model = get_model(training_set, False)\n",
        "  new_list = listdir(Config.TEST_PATH)\n",
        "  total_loss = []\n",
        "  for f in new_list:\n",
        "      #Prateek control images, 31 images\n",
        "      directory_path = join(Config.TEST_PATH, f)\n",
        "      test = get_single_test(directory_path)\n",
        "      print(\"got test\")\n",
        "      sz = test.shape[0] - 15\n",
        "      sequences = np.zeros((sz, 15, 256, 256, 3))\n",
        "      # apply the sliding window technique to get the sequences\n",
        "      for i in range(0, sz):\n",
        "          clip = np.zeros((15, 256, 256, 3))\n",
        "          for j in range(0, 15):\n",
        "              clip[j] = test[i + j, :, :, :]\n",
        "          sequences[i] = clip\n",
        "      reconstructed_sequences = model.predict(sequences,batch_size=2)\n",
        "      sequences_reconstruction_cost = np.array([np.linalg.norm(np.subtract(sequences[i],reconstructed_sequences[i])) for i in range(0,sz)])\n",
        "      sa = (sequences_reconstruction_cost - np.min(sequences_reconstruction_cost)) / np.max(sequences_reconstruction_cost)\n",
        "      loss = 1 - sum(sa)/len(sa)\n",
        "      total_loss.append((loss, f))\n",
        "  return total_loss\n",
        "        "
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQUrB-Lmn7MK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "3eb4e3ad-8d28-42b9-9905-4dc3ebfd6370"
      },
      "source": [
        "training_set, list_of_movies = get_training_set()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Movie_11\n",
            "looping...\n",
            "Movie_14\n",
            "looping...\n",
            "Movie_17\n",
            "looping...\n",
            "Movie_16\n",
            "looping...\n",
            "Movie_19\n",
            "looping...\n",
            "Movie_6\n",
            "looping...\n",
            "Movie_12\n",
            "looping...\n",
            "Movie_8\n",
            "looping...\n",
            "Movie_31\n",
            "looping...\n",
            "Movie_2\n",
            "looping...\n",
            "Movie_23\n",
            "done looping.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcZ1_wZV2_Eh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###Run this code to see what images the machine learning model is taking in! Seperates every 10 images (if you are using more or fewer images\n",
        "###together can update for that by changing count == n where n is the number of frames the model sees at a time)\n",
        "import time\n",
        "count = 0\n",
        "print(len(training_set))\n",
        "for j in range(len(training_set)):\n",
        "  print(training_set[j].shape)\n",
        "  for i in range(len(training_set[j])):\n",
        "    new_training_set = (training_set[j][i]*255).astype(np.uint8)\n",
        "    img = Image.fromarray(new_training_set, 'RGB')\n",
        "    display(img)\n",
        "    count += 1\n",
        "    if count == 10:\n",
        "      count = 0\n",
        "      print('--------------------------------------')\n",
        "    time.sleep(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3m1fGACvraE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e4ee5bf5-91a5-4575-f3aa-b8790801878b"
      },
      "source": [
        "evaluate(training_set, True)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "starting\n",
            "4\n",
            "5\n",
            "6\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "time_distributed_1 (TimeDist (None, 15, 64, 64, 128)   46592     \n",
            "_________________________________________________________________\n",
            "layer_normalization_1 (Layer (None, 15, 64, 64, 128)   256       \n",
            "_________________________________________________________________\n",
            "time_distributed_2 (TimeDist (None, 15, 32, 32, 64)    204864    \n",
            "_________________________________________________________________\n",
            "conv_lst_m2d_1 (ConvLSTM2D)  (None, 15, 32, 32, 64)    295168    \n",
            "_________________________________________________________________\n",
            "layer_normalization_2 (Layer (None, 15, 32, 32, 64)    128       \n",
            "_________________________________________________________________\n",
            "conv_lst_m2d_2 (ConvLSTM2D)  (None, 15, 32, 32, 32)    110720    \n",
            "_________________________________________________________________\n",
            "layer_normalization_3 (Layer (None, 15, 32, 32, 32)    64        \n",
            "_________________________________________________________________\n",
            "conv_lst_m2d_3 (ConvLSTM2D)  (None, 15, 32, 32, 64)    221440    \n",
            "_________________________________________________________________\n",
            "layer_normalization_4 (Layer (None, 15, 32, 32, 64)    128       \n",
            "_________________________________________________________________\n",
            "layer_normalization_5 (Layer (None, 15, 32, 32, 64)    128       \n",
            "_________________________________________________________________\n",
            "time_distributed_3 (TimeDist (None, 15, 64, 64, 64)    102464    \n",
            "_________________________________________________________________\n",
            "layer_normalization_6 (Layer (None, 15, 64, 64, 64)    128       \n",
            "_________________________________________________________________\n",
            "time_distributed_4 (TimeDist (None, 15, 256, 256, 128) 991360    \n",
            "_________________________________________________________________\n",
            "layer_normalization_7 (Layer (None, 15, 256, 256, 128) 256       \n",
            "_________________________________________________________________\n",
            "time_distributed_5 (TimeDist (None, 15, 256, 256, 3)   46467     \n",
            "=================================================================\n",
            "Total params: 2,020,163\n",
            "Trainable params: 2,020,163\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "92/92 [==============================] - 71s 773ms/step - loss: 0.0190\n",
            "Epoch 2/10\n",
            "92/92 [==============================] - 60s 652ms/step - loss: 0.0080\n",
            "Epoch 3/10\n",
            "92/92 [==============================] - 60s 654ms/step - loss: 0.0057\n",
            "Epoch 4/10\n",
            "92/92 [==============================] - 60s 652ms/step - loss: 0.0051\n",
            "Epoch 5/10\n",
            "92/92 [==============================] - 60s 655ms/step - loss: 0.0048\n",
            "Epoch 6/10\n",
            "92/92 [==============================] - 60s 653ms/step - loss: 0.0044\n",
            "Epoch 7/10\n",
            "92/92 [==============================] - 60s 652ms/step - loss: 0.0041\n",
            "Epoch 8/10\n",
            "92/92 [==============================] - 60s 653ms/step - loss: 0.0040\n",
            "Epoch 9/10\n",
            "92/92 [==============================] - 60s 652ms/step - loss: 0.0039\n",
            "Epoch 10/10\n",
            "92/92 [==============================] - 60s 652ms/step - loss: 0.0038\n",
            "got model\n",
            "got test\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTFtHYOw0-KZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "41eac7f5-9c2e-4ceb-adc5-d2bc3b4b0876"
      },
      "source": [
        "print(get_accuracy_WT(list_of_movies))\n",
        "print(get_accuracy_mut())"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Movie_20\n",
            "1\n",
            "got test\n",
            "Movie_30\n",
            "2\n",
            "got test\n",
            "Movie_33\n",
            "3\n",
            "got test\n",
            "Movie_21\n",
            "4\n",
            "got test\n",
            "Movie_9\n",
            "5\n",
            "got test\n",
            "Movie_26\n",
            "6\n",
            "[(0.09027336332499611, 'Movie_20'), (0.06866772743203753, 'Movie_30'), (0.1066359084117012, 'Movie_33'), (0.09305900587623779, 'Movie_21'), (0.09368018234513745, 'Movie_9')]\n",
            "got test\n",
            "got test\n",
            "got test\n",
            "got test\n",
            "[(0.0343838417087487, 'Spn_01'), (0.03556531240156787, 'Spn_02'), (0.14028606884359207, 'SPN_6'), (0.23704111258956825, 'Test_errorinMovie_01')]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}